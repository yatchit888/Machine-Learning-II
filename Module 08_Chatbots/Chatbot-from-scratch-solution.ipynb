{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Chatbot from Scratch using Python and Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications\n",
    "- FAQ bots\n",
    "- Recommendations\n",
    "- Airports\n",
    "- Taxi Bookings\n",
    "- Hotel Bookings\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot architecture\n",
    "- Humans (No engineering involved)\n",
    "- Rule-based (Regular Expressions)\n",
    "- Predictive (Retrieval Based)\n",
    "- Generative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - Finding Intents\n",
    "- where is my hotel\n",
    "    - where is my hotel\n",
    "    - hotel location/\n",
    "    - how do i get to the hotel?\n",
    "- when is checkout_time\n",
    "    - when is the checkout time?\n",
    "    - when do i need to check out?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_phrases = {\n",
    "    \"help-me\": ' '.join([\"I have a problem\",\n",
    "                         \"Hey i need some answers\",\n",
    "                         \"Can you help me with this?\",\n",
    "                         \"I need help\",\n",
    "                         \"Please help me\"\n",
    "                        ]),\n",
    "    \"alcohol-addiction\": ' '.join([\"I am addicted to alcohol\",\n",
    "                                   \"I love alcohol daily\",\n",
    "                                   \"I am an alcoholic\"\n",
    "                                  ]),\n",
    "    \"depression-problem\": ' '.join([\"I am depressed\",\n",
    "                                   \"I am lonely\",\n",
    "                                   \"I dont have friends\",\n",
    "                                   \"I am alone\",\n",
    "                                   \"I am always sad\",\n",
    "                                   \"Why am I sad all the time?\"\n",
    "                                   ]),\n",
    "    \"greeting\": ' '.join([\"Hi\",\n",
    "                         \"Hey there\",\n",
    "                          \"Hola\",\n",
    "                          \"Hi How are you doing?\"\n",
    "                         ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'help-me': 'I have a problem Hey i need some answers Can you help me with this? I need help Please help me',\n",
       " 'alcohol-addiction': 'I am addicted to alcohol I love alcohol daily I am an alcoholic',\n",
       " 'depression-problem': 'I am depressed I am lonely I dont have friends I am alone I am always sad Why am I sad all the time?',\n",
       " 'greeting': 'Hi Hey there Hola Hi How are you doing?'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_documents = list(training_phrases.values())\n",
    "labels = list(training_phrases.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have a problem Hey i need some answers Can you help me with this? I need help Please help me',\n",
       " 'I am addicted to alcohol I love alcohol daily I am an alcoholic',\n",
       " 'I am depressed I am lonely I dont have friends I am alone I am always sad Why am I sad all the time?',\n",
       " 'Hi Hey there Hola Hi How are you doing?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'have', 'a', 'problem', 'Hey', 'i', 'need', 'some', 'answers', 'Can', 'you', 'help', 'me', 'with', 'this', '?', 'I', 'need', 'help', 'Please', 'help', 'me'], ['I', 'am', 'addicted', 'to', 'alcohol', 'I', 'love', 'alcohol', 'daily', 'I', 'am', 'an', 'alcoholic'], ['I', 'am', 'depressed', 'I', 'am', 'lonely', 'I', 'dont', 'have', 'friends', 'I', 'am', 'alone', 'I', 'am', 'always', 'sad', 'Why', 'am', 'I', 'sad', 'all', 'the', 'time', '?'], ['Hi', 'Hey', 'there', 'Hola', 'Hi', 'How', 'are', 'you', 'doing', '?']]\n",
      "[['I', 'have', 'a', 'problem', 'Hey', 'i', 'need', 'some', 'answers', 'Can', 'you', 'help', 'me', 'with', 'this', '?', 'I', 'need', 'help', 'Please', 'help', 'me'], ['I', 'am', 'addicted', 'to', 'alcohol', 'I', 'love', 'alcohol', 'daily', 'I', 'am', 'an', 'alcoholic'], ['I', 'am', 'depressed', 'I', 'am', 'lonely', 'I', 'dont', 'have', 'friends', 'I', 'am', 'alone', 'I', 'am', 'always', 'sad', 'Why', 'am', 'I', 'sad', 'all', 'the', 'time', '?'], ['Hi', 'Hey', 'there', 'Hola', 'Hi', 'How', 'are', 'you', 'doing', '?']]\n",
      "[['I', 'have', 'a', 'problem', 'Hey', 'i', 'need', 'some', 'answers', 'Can', 'you', 'help', 'me', 'with', 'this', '?', 'I', 'need', 'help', 'Please', 'help', 'me'], ['I', 'am', 'addicted', 'to', 'alcohol', 'I', 'love', 'alcohol', 'daily', 'I', 'am', 'an', 'alcoholic'], ['I', 'am', 'depressed', 'I', 'am', 'lonely', 'I', 'dont', 'have', 'friends', 'I', 'am', 'alone', 'I', 'am', 'always', 'sad', 'Why', 'am', 'I', 'sad', 'all', 'the', 'time', '?'], ['Hi', 'Hey', 'there', 'Hola', 'Hi', 'How', 'are', 'you', 'doing', '?']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = tuple(set(stopwords.words('english'))) \n",
    "\n",
    "word_tokens = []\n",
    "for sent in training_documents:\n",
    "    word_tokens.append(word_tokenize(sent))\n",
    "\n",
    "print(word_tokens)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 25)\t2\n",
      "  (0, 29)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 37)\t1\n",
      "  (0, 17)\t3\n",
      "  (0, 24)\t2\n",
      "  (0, 36)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 26)\t1\n",
      "  (1, 6)\t2\n",
      "  (1, 0)\t1\n",
      "  (1, 34)\t1\n",
      "  (1, 1)\t2\n",
      "  (1, 23)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 16)\t1\n",
      "  (2, 6)\t5\n",
      "  (2, 12)\t1\n",
      "  (2, 22)\t1\n",
      "  (2, 14)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 28)\t2\n",
      "  (2, 35)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 30)\t1\n",
      "  (2, 33)\t1\n",
      "  (3, 18)\t1\n",
      "  (3, 37)\t1\n",
      "  (3, 19)\t2\n",
      "  (3, 31)\t1\n",
      "  (3, 20)\t1\n",
      "  (3, 21)\t1\n",
      "  (3, 9)\t1\n",
      "  (3, 13)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['addicted',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'all',\n",
       " 'alone',\n",
       " 'always',\n",
       " 'am',\n",
       " 'an',\n",
       " 'answers',\n",
       " 'are',\n",
       " 'can',\n",
       " 'daily',\n",
       " 'depressed',\n",
       " 'doing',\n",
       " 'dont',\n",
       " 'friends',\n",
       " 'have',\n",
       " 'help',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'hola',\n",
       " 'how',\n",
       " 'lonely',\n",
       " 'love',\n",
       " 'me',\n",
       " 'need',\n",
       " 'please',\n",
       " 'problem',\n",
       " 'sad',\n",
       " 'some',\n",
       " 'the',\n",
       " 'there',\n",
       " 'this',\n",
       " 'time',\n",
       " 'to',\n",
       " 'why',\n",
       " 'with',\n",
       " 'you']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(training_documents)\n",
    "print(X)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alcohol-addiction'], dtype='<U18')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_queries = [\"I love everything related to C2H50H\"]\n",
    "queries = vectorizer.transform(raw_queries)\n",
    "predictions = classifier.predict(queries)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(raw_queries):\n",
    "    queries = vectorizer.transform(raw_queries)\n",
    "    return classifier.predict(queries)\n",
    "\n",
    "predicted = predict([\"I am very much sad\", \"can we talk?\", \"Can you help me?\", \"i take wine everyday and i cant live without it\"])\n",
    "expected = [\"depression-problem\", \"help-me\", \"help-me\", \"alcohol-addiction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['depression-problem', 'help-me', 'help-me', 'alcohol-addiction'],\n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1.]),\n",
       " array([1., 1., 1.]),\n",
       " array([1., 1., 1.]),\n",
       " array([1, 1, 2]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = precision_recall_fscore_support(expected, predicted)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': array([1., 1., 1.]), 'r': array([1., 1., 1.]), 'f1': array([1., 1., 1.])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {}\n",
    "(metrics['p'], metrics['r'], metrics['f1'], _) = evaluation\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges / Questions to be answered\n",
    "- Return the answer\n",
    "- Exclude unimportant words(\"stop words\")\n",
    "- Handle synonyms (e.g. \"lobby\" = \"front desk\")\n",
    "- Handle typos\n",
    "- Return \"Unknown\"\n",
    "- Handle a entity/parameter (\"set my check out time to 3 PM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning the Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = {\n",
    "    \"depression-response\": \"Hi, please do not worry. I am here to help you.\",\n",
    "    \"help-response\": \"Hi there, yes ofcourse. I am at your service. How can I help you today?\",\n",
    "    \"alcohol-response\": \"Good to know that. Now I can work with you in making you better.\",\n",
    "    \"greeting-response\": \"Hi there my friend. How are you today?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good to know that. Now I can work with you in making you better.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses['alcohol-response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alcohol-addiction'], dtype='<U18')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = predict([\"i take wine everyday and i cant live without it\"])\n",
    "# expected = [\"alcohol-addiction\"]\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_response(raw_queries):\n",
    "    predicted = predict(raw_queries)\n",
    "    print(predicted[0])\n",
    "    if predicted[0] == \"alcohol-addiction\":\n",
    "        return(responses[\"alcohol-response\"])\n",
    "    else:\n",
    "        return \"You are not an alcoholic!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alcohol-addiction\n",
      "Good to know that. Now I can work with you in making you better.\n"
     ]
    }
   ],
   "source": [
    "bot_response = send_response([\"i take wine everyday and i cant live without it\"])\n",
    "print(bot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'Hey', 'Hola', 'Hi', 'How', '?']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = tuple(set(stopwords.words('english'))) \n",
    "\n",
    "for sent in training_documents:\n",
    "    word_tokens = word_tokenize(sent)\n",
    "    \n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typos - Edit distance, Phonetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['problem', 'Hey', 'need', 'some', 'answers', 'help', 'me', 'with', 'this', 'Please', 'addicted', 'alcohol', 'love', 'daily', 'alcoholic', 'depressed', 'lonely', 'dont', 'friends', 'alone', 'always', 'sad', 'Why', 'all', 'time', 'Hi', 'Hey', 'there', 'Hola', 'Hi', 'How', 'are', 'you', 'doing', '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import get_close_matches\n",
    "def spell_checker(token):\n",
    "    spelling_error_flag = False\n",
    "    corrected_word = ''\n",
    "    if len(get_close_matches(token, tokens, n=1, cutoff=0.80)) > 0:\n",
    "        corrected_word = get_close_matches(token, tokens, n=1, cutoff=0.80)[0]\n",
    "        spelling_error_flag = True\n",
    "        return corrected_word, spelling_error_flag\n",
    "    else:\n",
    "        return corrected_word, spelling_error_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alone'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_word, flag = spell_checker('lone')\n",
    "corrected_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('alone.s.01'), Synset('alone.s.02'), Synset('alone.s.03'), Synset('alone.s.04'), Synset('entirely.r.02'), Synset('alone.r.02')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "syns = wordnet.synsets(\"alone\")\n",
    "print(syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
