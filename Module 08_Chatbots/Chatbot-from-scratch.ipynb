{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Chatbot from Scratch using Python and Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications\n",
    "- FAQ bots\n",
    "- Recommendations\n",
    "- Airports\n",
    "- Taxi Bookings\n",
    "- Hotel Bookings\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot architecture\n",
    "- Humans (No engineering involved)\n",
    "- Rule-based (Regular Expressions)\n",
    "- Predictive (Retrieval Based)\n",
    "- Generative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - Finding Intents\n",
    "- where is my hotel\n",
    "    - where is my hotel\n",
    "    - hotel location/\n",
    "    - how do i get to the hotel?\n",
    "- when is checkout_time\n",
    "    - when is the checkout time?\n",
    "    - when do i need to check out?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Creating a chatbot that will help you answer some basic questions\n",
    "- Import the libraries\n",
    "- Create training phrases\n",
    "- Collect all user utterances\n",
    "- Create Bag of Words Model\n",
    "- Create a Classifier\n",
    "- Train the classifier\n",
    "- Predict on the trained classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training phrases\n",
    "...... create more like these for your own domain chatbot\n",
    "- intent: [user utterances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_phrases = {\n",
    "    \"help-me\": ' '.join([\"I have a problem\",\n",
    "                         \"Hey i need some answers\",\n",
    "                         \"Can you help me with this?\",\n",
    "                         \"I need help\",\n",
    "                         \"Please help me\"\n",
    "                        ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'help-me': 'I have a problem Hey i need some answers Can you help me with this? I need help Please help me'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect all training documents as user utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_documents = list(training_phrases.values())\n",
    "labels = list(training_phrases.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have a problem Hey i need some answers Can you help me with this? I need help Please help me']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the user utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'have', 'a', 'problem', 'Hey', 'i', 'need', 'some', 'answers', 'Can', 'you', 'help', 'me', 'with', 'this', '?', 'I', 'need', 'help', 'Please', 'help', 'me']]\n",
      "[['I', 'have', 'a', 'problem', 'Hey', 'i', 'need', 'some', 'answers', 'Can', 'you', 'help', 'me', 'with', 'this', '?', 'I', 'need', 'help', 'Please', 'help', 'me']]\n",
      "['I', 'problem', 'Hey', 'need', 'answers', 'Can', 'help', '?', 'I', 'need', 'help', 'Please', 'help']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "word_tokens = []\n",
    "for sent in training_documents:\n",
    "    word_tokens.append(word_tokenize(sent))\n",
    "\n",
    "print(word_tokens)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens[0] if not w in stop_words]\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bag of Words Model\n",
    "- Import CountVectorizer\n",
    "- fit_transform on training documents\n",
    "- get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 25)\t2\n",
      "  (0, 29)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 37)\t1\n",
      "  (0, 17)\t3\n",
      "  (0, 24)\t2\n",
      "  (0, 36)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 26)\t1\n",
      "  (1, 6)\t2\n",
      "  (1, 0)\t1\n",
      "  (1, 34)\t1\n",
      "  (1, 1)\t2\n",
      "  (1, 23)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 16)\t1\n",
      "  (2, 6)\t5\n",
      "  (2, 12)\t1\n",
      "  (2, 22)\t1\n",
      "  (2, 14)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 28)\t2\n",
      "  (2, 35)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 30)\t1\n",
      "  (2, 33)\t1\n",
      "  (3, 18)\t1\n",
      "  (3, 37)\t1\n",
      "  (3, 19)\t2\n",
      "  (3, 31)\t1\n",
      "  (3, 20)\t1\n",
      "  (3, 21)\t1\n",
      "  (3, 9)\t1\n",
      "  (3, 13)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['addicted',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'all',\n",
       " 'alone',\n",
       " 'always',\n",
       " 'am',\n",
       " 'an',\n",
       " 'answers',\n",
       " 'are',\n",
       " 'can',\n",
       " 'daily',\n",
       " 'depressed',\n",
       " 'doing',\n",
       " 'dont',\n",
       " 'friends',\n",
       " 'have',\n",
       " 'help',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'hola',\n",
       " 'how',\n",
       " 'lonely',\n",
       " 'love',\n",
       " 'me',\n",
       " 'need',\n",
       " 'please',\n",
       " 'problem',\n",
       " 'sad',\n",
       " 'some',\n",
       " 'the',\n",
       " 'there',\n",
       " 'this',\n",
       " 'time',\n",
       " 'to',\n",
       " 'why',\n",
       " 'with',\n",
       " 'you']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bag of words model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Classifier\n",
    "- Import\n",
    "- Create\n",
    "- Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on user utterances\n",
    "- create a user query\n",
    "- Transform the query using vectorizer\n",
    "- Run prediction on the transformed query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['depression-problem'], dtype='<U18')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together inside predict( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(raw_queries):\n",
    "    \n",
    "    return classifier.predict(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predict([\"I am very much sad\", \"can we talk?\", \"Can you help me?\", \"i take wine everyday and i cant live without it\"])\n",
    "expected = [\"depression-problem\", \"help-me\", \"help-me\", \"alcohol-addiction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['depression-problem', 'help-me', 'help-me', 'alcohol-addiction'],\n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1.]),\n",
       " array([1., 1., 1.]),\n",
       " array([1., 1., 1.]),\n",
       " array([1, 1, 2]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = precision_recall_fscore_support(expected, predicted)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': array([1., 1., 1.]), 'r': array([1., 1., 1.]), 'f1': array([1., 1., 1.])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {}\n",
    "(metrics['p'], metrics['r'], metrics['f1'], _) = evaluation\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges / Questions to be answered\n",
    "- Return the answer\n",
    "- Exclude unimportant words(\"stop words\")\n",
    "- Handle synonyms (e.g. \"lobby\" = \"front desk\")\n",
    "- Handle typos\n",
    "- Return \"Unknown\"\n",
    "- Handle a entity/parameter (\"set my check out time to 3 PM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning the Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = {\n",
    "    .... fill the responses for each intent\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good to know that. Now I can work with you in making you better.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses['alcohol-response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alcohol-addiction'], dtype='<U18')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = predict([\"i take wine everyday and i cant live without it\"])\n",
    "# expected = [\"alcohol-addiction\"]\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_response(raw_queries):\n",
    "    predicted = predict(raw_queries)\n",
    "    print(predicted[0])\n",
    "    if predicted[0] == \"alcohol-addiction\":\n",
    "        return(responses[\"alcohol-response\"])\n",
    "    else:\n",
    "        return \"You are not an alcoholic!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alcohol-addiction\n",
      "Good to know that. Now I can work with you in making you better.\n"
     ]
    }
   ],
   "source": [
    "bot_response = send_response([\"i take wine everyday and i cant live without it\"])\n",
    "print(bot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typos - Edit distance, Phonetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['problem', 'Hey', 'need', 'some', 'answers', 'help', 'me', 'with', 'this', 'Please', 'addicted', 'alcohol', 'love', 'daily', 'alcoholic', 'depressed', 'lonely', 'dont', 'friends', 'alone', 'always', 'sad', 'Why', 'all', 'time', 'Hi', 'Hey', 'there', 'Hola', 'Hi', 'How', 'are', 'you', 'doing', '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import get_close_matches\n",
    "def spell_checker(token):\n",
    "    # Implement this function by checking the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alcoholic'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_word, flag = spell_checker('alcholic')\n",
    "corrected_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('wine.n.01'), Synset('wine.n.02'), Synset('wine.v.01'), Synset('wine.v.02')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "syns = wordnet.synsets(\"wine\")\n",
    "print(syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
