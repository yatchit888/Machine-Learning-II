{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Phrase Extraction\n",
    "## This notebook outlines the concepts involved in extracting keyword phrases in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: **Identify keywords in a piece of text**\n",
    "\n",
    "Identify **words that are very important** in a piece of text\n",
    "\n",
    "### Possible Solutions:\n",
    "- TF-IDF (already seen)\n",
    "- Noun Chunks\n",
    "- - Specialized Keyword Extraction algorithms\n",
    "    - TextRank\n",
    "    - SGRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Textacy is an excellent library that uses several information extraction functions, many of them based on regular expression patterns and heuristics to address extracting specific expressions such as acronyms and quotations. Apart from these, one can also extract matching custom regular expressions including POS tag patterns, or look for statements involving an entity, subject-verb-object tuples etc. \n",
    "\n",
    "We will use Textacy to extract keywords from documents\n",
    "\n",
    "Documentaion: https://textacy.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textacy==0.9.1\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy.ke\n",
    "from textacy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a spacy model, which will be used for all further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = textacy.load_spacy_lang(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a sample text to find keywords\n",
    "- kpe_sample_text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = open('kpe_sample_text.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the text into a spacy document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = textacy.make_spacy_doc(mytext, lang=en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Noun Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Common NLP Tasks, list, most commonly researched tasks, natural language processing, tasks, direct real-world applications, others, subtasks, larger tasks, natural language processing tasks, they, categories, convenience, coarse division, Text and speech processing, Optical character recognition, (OCR, image, printed text, corresponding text, Speech recognition, sound clip, person, people, textual representation, speech, opposite, text, speech, extremely difficult problems, natural speech, pauses, successive words, speech segmentation, necessary subtask, speech recognition, most spoken languages, sounds, process, coarticulation, conversion, analog signal, characters, very difficult process, words, same language, people, different accents, speech recognition software, wide variety, input, terms, textual equivalent, Speech segmentation, sound clip, person, people, it, words, subtask, speech recognition, it, speech, text, units, spoken representation, Text, speech, Word segmentation, Tokenization, chunk, continuous text, separate words, language, English, words, spaces, written languages, Chinese, Japanese, Thai, word boundaries, a fashion, languages, text segmentation, significant task, knowledge, vocabulary, morphology, words, language, process, cases, bag, words, (BOW) creation, data mining, Morphological analysis, Lemmatization, task, inflectional endings, base, dictionary form, word, lemma, Lemmatization, technique, words, normalized form, case, transformation, dictionary, words, actual form.[19, Morphological segmentation, Separate words, individual morphemes, class, morphemes, difficulty, task, complexity, morphology, (i.e., the structure, words, language, English, fairly simple morphology, especially inflectional morphology, it, task, possible forms, word, separate words, languages, Meitei,[20, highly agglutinated Indian language, an approach, dictionary entry, thousands, possible word forms, speech, sentence, part, speech, POS, word, Many words, especially common ones, multiple parts, speech, example, \"book, noun, (\"the book, table, flight, noun, at least five different parts, speech, process, inflected (or sometimes derived) words, base form, root, yields, similar results, lemmatization, grounds, rules, not a dictionary, Syntactic analysis, Grammar induction[21, formal grammar, language's syntax, Sentence breaking, sentence boundary disambiguation, chunk, text, sentence boundaries, Sentence boundaries, periods, other punctuation marks, same characters, other purposes, abbreviations, Parsing, parse tree, grammatical analysis, given sentence, grammar, natural languages, ambiguous and typical sentences, multiple possible analyses, typical sentence, thousands, potential parses, human, two primary types, dependency parsing, constituency parsing, Dependency parsing, relationships, words, sentence, things, primary objects, predicates, constituency parsing, parse tree, probabilistic context-free grammar, PCFG, stochastic grammar, Lexical semantics, individual words, context, Lexical semantics, What, computational meaning, individual words, context, Distributional semantics, we, semantic representations, data, entity recognition, (NER, stream, text, items, text map, proper names, people, places, what, type, such name, e.g. person, location, capitalization, named entities, languages, English, information, type, named entity, case, example, first letter, sentence, entities, several words, many other languages, non-Western scripts, Arabic, capitalization, capitalization, it, names, example, nouns, they, names, Spanish, names, adjectives, Sentiment analysis, multimodal sentiment analysis, subjective information, set, documents, online reviews, \"polarity, specific objects, It, trends, public opinion, social media, marketing, Terminology extraction, goal, terminology extraction, relevant terms, given corpus, Word sense disambiguation, Many words, more than one meaning, we, meaning, most sense, context, problem, we, list, words, associated word senses, dictionary, online resource, WordNet, Relational semantics, semantics, individual sentences, Relationship extraction, chunk, text, relationships, named entities, who, whom, Semantic Parsing, piece, text, typically a sentence, formal representation, semantics, graph, accordance, logical formalism, DRT parsing, challenge, aspects, several more elementary NLP tasks, semantics, (e.g., semantic role labelling, word sense disambiguation, full-fledged discourse analysis, , discourse analysis, coreference, Semantic Role Labelling, single sentence, semantic predicates, (e.g., verbal frames, frame elements, semantic roles, Discourse, (semantics, individual sentences, Coreference resolution, sentence, larger chunk, text, words, (\"mentions, same objects, \"entities, Anaphora resolution, specific example, task, pronouns, nouns, names, they, more general task, coreference resolution, so-called \"bridging relationships, expressions, example, sentence, He, John's house, front door, front door, referring expression, bridging relationship, fact, door, front door, John's house, other structure, Discourse analysis, rubric, several related tasks, One task, discourse structure, connected text, i.e. the nature, discourse relationships, sentences, e.g. elaboration, explanation, contrast, possible task, speech acts, chunk, text, (e.g. yes-no question, content question, statement, assertion, Implicit Semantic Role Labelling, single sentence, semantic predicates, (e.g., verbal frames, explicit semantic roles, current sentence, Semantic Role Labelling, semantic roles, current sentence, them, arguments, text, local text, closely related task, zero anaphora resolution, extension, coreference resolution, pro-drop languages, Textual entailment, two text fragments, other's negation, Topic segmentation, recognition, chunk, text, it, segments, topic, topic, segment, Higher-level NLP applications, Automatic summarization, text summarization, readable summary, chunk, text, summaries, text, known type, research papers, articles, financial section, newspaper, Book generation, Not an NLP task, extension, Natural Language Generation, other NLP tasks, creation, full-fledged books, first machine-generated book, rule-based system, policeman's beard, first published work, neural network, 1 the Road, novel, sixty million words, Both these systems, basically elaborate but non-sensical (semantics-free) language models, first machine-generated science book, Racter, Road, factual knowledge, text summarization, Dialogue management, Computer systems, human, Document AI, Document AI platform, top, NLP technology, users, prior experience, artificial intelligence, computer, specific data, they, different document types, NLP-powered Document AI, non-technical teams, information, documents, example, Grammatical error correction, Grammatical error detection, correction, great band-width, problems, levels, linguistic analysis, (phonology/orthography, morphology, syntax, semantics, pragmatics, Grammatical error correction, it, hundreds of millions, people, English, second language, It, number, shared tasks, orthography, morphology, syntax, certain aspects, semantics, development, powerful neural language models, GPT-2, largely solved problem, Machine translation, Automatically translate, text, one human language, most difficult problems, member, class, problems, different types, knowledge, humans, grammar, semantics, real world, Natural language generation, (NLG, information, computer databases, semantic intents, readable human language, Natural language understanding, (NLU, chunks, text, more formal representations, first-order logic structures, computer programs, Natural language understanding, identification, multiple possible semantics, natural language expression, form, organized notations, natural language concepts, Introduction, creation, language metamodel, ontology, empirical solutions, explicit formalization, natural language semantics, confusions, implicit assumptions, closed-world assumption, CWA, open-world assumption, True/False, construction, basis, semantics, Question answering, human-language question, answer, Typical questions, specific right answer, What, capital, Canada, open-ended questions, What, meaning, life, Recent works, even more complex questions]\n"
     ]
    }
   ],
   "source": [
    "print([chunk for chunk in textacy.extract.noun_chunks(doc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural language semantic', 0.01826851160612513),\n",
       " ('natural language processing task', 0.018092527578712124),\n",
       " ('language text segmentation', 0.016815366400779165),\n",
       " ('possible word form', 0.012521268238753758),\n",
       " ('natural language expression', 0.012062163598739382)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textacy.ke.textrank(doc, topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get more keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural language semantic', 0.01826851160612513),\n",
       " ('natural language processing task', 0.018092527578712124),\n",
       " ('language text segmentation', 0.016815366400779165),\n",
       " ('possible word form', 0.012521268238753758),\n",
       " ('natural language expression', 0.012062163598739382),\n",
       " ('readable human language', 0.011964826503084598),\n",
       " ('powerful neural language model', 0.011901252212139994),\n",
       " ('natural language generation', 0.011871126457925964),\n",
       " ('multiple possible semantic', 0.011691648529128245),\n",
       " ('language question', 0.011681325715062103),\n",
       " ('natural language understanding', 0.011676450614983213),\n",
       " ('natural language concept', 0.011447215522776017),\n",
       " ('implicit semantic role labelling', 0.011167395093629413),\n",
       " ('NLP task proper', 0.010611921448657437),\n",
       " ('elementary NLP task', 0.01021661374848852),\n",
       " ('word sense disambiguation', 0.009974047524682016),\n",
       " ('explicit semantic role', 0.009904684234914677),\n",
       " ('separate word', 0.009549844032787299),\n",
       " ('word segmentation', 0.00953080397548952),\n",
       " ('indian language', 0.00945148317496164)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textacy.ke.textrank(doc, topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords using TextRank algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural language semantic',\n",
       " 'natural language processing task',\n",
       " 'language text segmentation',\n",
       " 'possible word form',\n",
       " 'natural language expression',\n",
       " 'readable human language',\n",
       " 'powerful neural language model',\n",
       " 'natural language generation',\n",
       " 'multiple possible semantic',\n",
       " 'language question']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[kps for kps, weights in textacy.ke.textrank(doc, normalize=\"lemma\", topn=10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords using SGRank algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural language',\n",
       " 'speech recognition',\n",
       " 'word',\n",
       " 'text',\n",
       " 'separate word',\n",
       " 'task',\n",
       " 'semantic role',\n",
       " 'word sense',\n",
       " 'NLP',\n",
       " 'sentence']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[kps for kps, weights in textacy.ke.sgrank(doc, topn=10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue: **Overlapping key phrases**\n",
    "\n",
    "Solution: **aggregage_term_variants**\n",
    "- Choosing one of the grouped terms per item will give us a list of non-overlapping key phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'speech recognition'}, {'natural language'}, {'semantic role'}, {'separate word'}, {'word sense'}, {'sentence'}, {'text'}, {'word'}, {'task'}, {'NLP'}]\n"
     ]
    }
   ],
   "source": [
    "terms = set([term for term,weight in textacy.ke.sgrank(doc)])\n",
    "print(textacy.ke.utils.aggregate_term_variants(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
