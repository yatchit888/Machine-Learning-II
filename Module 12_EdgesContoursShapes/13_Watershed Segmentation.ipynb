{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WATERSHED SEGMENTATION ALGORITHM\n",
    "Classic algorithm used for **segmentation** and is especially useful when extracting **touching or overlapping objects** in images\n",
    "\n",
    "When utilizing the watershed algorithm we must start with **user-defined markers**\n",
    "\n",
    "These markers can be either defined:\n",
    "- manually point-and-click\n",
    "- automatically or heuristically define them\n",
    "    - thresholding operations\n",
    "    - morphological operations\n",
    "    \n",
    "Based on these markers, the watershed algorithm treats pixels in our input image as **local elevation** (called a topography) — the method **“floods”** valleys, starting from the markers and moving outwards, until the valleys of different markers meet each other\n",
    "\n",
    "- In order to obtain an accurate watershed segmentation, the markers must be correctly placed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment and Extract objects \n",
    "- Import the libraries\n",
    "- Load the image\n",
    "- Apply Pyramid Mean Shift Filtering \n",
    "[PMSF]https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html#pyrmeanshiftfiltering\n",
    "- Convert the image into grayscale\n",
    "- Threshold the Mean Shifted image\n",
    "- Detect Contours using findContours()\n",
    "- Draw Contours using drawContours()\n",
    "- Display the extracted contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Pyramid Mean Shift Filtering\n",
    "cv2.PyrMeanShiftFiltering()\n",
    "- src\n",
    "    - The source 8-bit, 3-channel image\n",
    "- dst\n",
    "    - The destination image of the same format and the same size as the source\n",
    "- sp\n",
    "    - The spatial window radius\n",
    "- sr\n",
    "    - The color window radius\n",
    "- maxLevel\n",
    "    - Maximum level of the pyramid for the segmentation\n",
    "- termcrit\n",
    "    - Termination criteria: when to stop meanshift iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the image into Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold the image\n",
    "- Use OTSU Simple Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Contours\n",
    "**cv2.findContours()**\n",
    "- image (recommeded to send its copy rather the original)\n",
    "- type of contour\n",
    "    - cv2.RETR_EXTERNAL\n",
    "    - cv2.RETR_LIST\n",
    "    - cv2.RETR_COMP\n",
    "    - cv2.RETR_TREE\n",
    "- approximation of contour\n",
    "    - cv2.CHAIN_APPROX_SIMPLE\n",
    "    - cv2.CHAIN_APPROX_NONE\n",
    "- Returns a tuple\n",
    "    - output image after applying contour detection\n",
    "    - cnts list of contours detected\n",
    "    - hierarchy of the contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function - grab_contours( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_contours(cnts): \n",
    "    if len(cnts) == 2: \n",
    "        cnts = cnts[0]\n",
    "    elif len(cnts) == 3:\n",
    "        cnts = cnts[1]\n",
    "    else:\n",
    "        raise Exception((\"Contours tuple must have length 2 or \"\n",
    "                        \"3, otherwise OpenCV changed their cv2.findContours \" \n",
    "                        \"return signature yet again. \"\n",
    "                        \"Refer to OpenCV’s documentation in that case.\"))\n",
    "    return cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many contours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Contours\n",
    "cv2.drawContours()\n",
    "- image\n",
    "- contours list\n",
    "- contour index\n",
    "    - -1 --> draw all of the contours\n",
    "    - i --> draw single contour\n",
    "- color of the contour line\n",
    "    - Use green color\n",
    "- thickness of the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = image.copy()\n",
    "for (i, c) in enumerate(cnts):\n",
    "    # draw the contour\n",
    "    ((x, y), _) = cv2.minEnclosingCircle(c)\n",
    "    cv2.putText(image, \"#{}\".format(i + 1), (int(x) - 10, int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Extraction of Coins\", np.hstack([image, coins]))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following to install scipy, scikit-image, imutils\n",
    "# ! pip install scipy scikit-image imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watershed Segmentation\n",
    "\n",
    "#### Usual Steps\n",
    "- Load the image\n",
    "- Apply Pyramid Mean Shift Filtering \n",
    "- Convert the image into grayscale\n",
    "- Threshold the Mean Shifted image\n",
    "\n",
    "#### New Steps\n",
    "- Import new libraries\n",
    "- Euclidean Distance Transform (EDT)\n",
    "- Find Peaks in the Distance Map\n",
    "- Perform a Connected Component Analysis on the local peaks using 8-connectivity\n",
    "- Apply Watershed algorithm to get pixel labels\n",
    "- Draw Contours by looping through pixel lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import new libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean Distance Transform (EDT)\n",
    "Computes the Euclidean distance to the closest zero (background) pixel for each of the white (foreground) pixels and builds a distance map\n",
    "![Distance Map](https://raw.githubusercontent.com/subashgandyer/datasets/main/images/Watershed-EDT-DistanceMap.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FInding peaks in the distance map\n",
    "\n",
    "Peaks --> local maxima\n",
    "\n",
    "Please note a minimum 20 pixel distance between each peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connected Component Analysis\n",
    "[Wiki]https://en.wikipedia.org/wiki/Connected-component_labeling\n",
    "\n",
    "Use **8-connectivity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watershed Algorithm\n",
    "\n",
    "Watershed assumes **markers** as **local minima** (valleys) in our distance map\n",
    "\n",
    "Returns a matrix of **labels** for every pixel\n",
    "\n",
    "Each pixel value as a unique label value\n",
    "\n",
    "**Pixels that have the same label value belong to the same object**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many Contours found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw Contours\n",
    "- Loop over the unique labels returned by watershed algorithm\n",
    "- If it is not a background pixel\n",
    "    - Allocate memory for the label region and draw it on the mask\n",
    "    - Detect Contours in the mask and grab the largest one\n",
    "    - Draw a circle enclosing the object\n",
    "    - Place a number on the image\n",
    "- If it is a background pixel\n",
    "    - Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in np.unique(labels):\n",
    "    if label == 0:\n",
    "        continue\n",
    "        \n",
    "    mask = np.zeros(gray.shape, dtype=\"uint8\")\n",
    "    mask[labels == label] = 255\n",
    "    \n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = grab_contours(cnts)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    \n",
    "    ((x, y), r) = cv2.minEnclosingCircle(c)\n",
    "    cv2.circle(image, (int(x), int(y)), int(r), (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.putText(image, \"#{}\".format(label), (int(x) - 10, int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Watershed Extraction of coins\", np.hstack([coins, image]))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "Watershed algorithm is a classic segmentation algorithm used to detect and extract objects in images that are touching and/or overlapping\n",
    "\n",
    "To apply the watershed algorithm:\n",
    "- we need to define markers which correspond to the objects in our image\n",
    "- These markers can be either user-defined or we can apply image processing techniques (such as thresholding) to find the **markers** for us\n",
    "- When applying the watershed algorithm, it’s absolutely critical that we obtain accurate markers\n",
    "\n",
    "Given our markers:\n",
    "- we can compute the Euclidean Distance Transform\n",
    "- and pass the distance map to the watershed function itself, which **“floods”** valleys in the distance map, starting from the initial markers and moving outwards\n",
    "- Where the **“pools”** of water meet can be considered **boundary lines** in the segmentation process\n",
    "- The output of the watershed algorithm is a set of **labels**, where each label corresponds to a unique object in the image\n",
    "- loop over each of the labels individually and extract each object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
