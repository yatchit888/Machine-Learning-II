{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Convolutions\n",
    "## This notebook outlines the concepts of Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutions are one of the most critical, fundamental building-blocks in computer vision and image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Questions\n",
    "- What are Image Convolutions?\n",
    "- What do they do?\n",
    "- Why do we use them?\n",
    "- How do we apply them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolution** is simply an element-wise multiplication of two matrices followed by a sum\n",
    "- Take two matrices\n",
    "- Multiply them element-by-element (not a dot product)\n",
    "- Sum the elements together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uses**\n",
    "- blurring (average smoothing, Gaussian smoothing, median smoothing, etc.)\n",
    "- edge detection (Laplacian, Sobel, Scharr, Prewitt, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   \n",
    "### **Convolution**\n",
    "\n",
    "Image: multi-dimensional matrix\n",
    "   - width (Number of columns)\n",
    "   - height (Number of rows)\n",
    "   \n",
    "Kernel or Convolutional matrix\n",
    "   - Tiny matrix\n",
    "   - Usually a square matrix\n",
    "\n",
    "Tiny kernel **sits** on top of the big image and **slides** from left-to-right and top-to-bottom, applying a mathematical operation (i.e., a convolution) at each (x, y)-coordinate of the original image.\n",
    "\n",
    "It’s normal to **hand-define kernels** to obtain various image processing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Convolution](https://raw.githubusercontent.com/subashgandyer/datasets/main/images/Conv-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are sliding the kernel from left-to-right and top-to-bottom along the original image.\n",
    "\n",
    "At each (x, y)-coordinate of the original image, we stop and examine the neighborhood of pixels located at the center of the image kernel. We then take this neighborhood of pixels, convolve them with the kernel, and obtain a single output value. This output value is then stored in the output image at the same (x, y)-coordinates as the center of the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sqaure 3 x 3 kernel\n",
    "![Convolution](https://raw.githubusercontent.com/subashgandyer/datasets/main/images/Conv-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use an **odd kernel** size to ensure there is a valid integer (x, y)-coordinate at the center of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Convolution](https://raw.githubusercontent.com/subashgandyer/datasets/main/images/Conv-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a 3 x 3 matrix, the center of the matrix is obviously located at **x=1, y=1** where the top-left corner of the matrix is used as the origin and our coordinates are zero-indexed.\n",
    "\n",
    "With a 2 x 2 matrix, the center of this matrix would be located at **x=0.5, y=0.5** \n",
    "\n",
    "There is no such thing as pixel location (0.5, 0.5) — our pixel coordinates must be **integers**! \n",
    "\n",
    "This reasoning is exactly why we use **odd kernel sizes** — to always ensure there is a valid (x, y)-coordinate at the center of the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convolution requires three components:\n",
    "- An input image\n",
    "- A kernel matrix that we are going to apply and slide on the input image\n",
    "- An output image to store the output of the input image convolved with the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolution Steps**\n",
    "\n",
    "- Select an (x, y)-coordinate from the original image\n",
    "- Place the **center** of the kernel at this (x, y)-coordinate\n",
    "- Take the element-wise multiplication of the input image region and the kernel, then sum up the values of these multiplication operations into a single value. The sum of these multiplications is called the **kernel output**\n",
    "- Use the same (x, y)-coordinates from Step #1, but this time, store the kernel output in the same (x, y)-location as the output image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution Output = Kernel Matrix (3 x 3) * Image (3 x 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Convolution](https://raw.githubusercontent.com/subashgandyer/datasets/main/images/Conv-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Convolution](https://raw.githubusercontent.com/subashgandyer/datasets/main/images/Conv-5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.15.1 in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (from scikit-image) (1.19.2)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (from scikit-image) (1.5.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (from scikit-image) (3.3.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (from scikit-image) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (from scikit-image) (8.0.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (from scikit-image) (2020.10.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/subashgandyer/.local/lib/python3.8/site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/subashgandyer/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolve function (Custom helper function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(image, kernel):\n",
    "    # grab the spatial dimensions of the image, along with the spatial dimensions of the kernel\n",
    "    (iH, iW) = image.shape[:2]\n",
    "    (kH, kW) = kernel.shape[:2]\n",
    "    \n",
    "    # allocate memory for the output image, taking care to \"pad\" the borders of the input image so the spatial\n",
    "    # size (i.e., width and height) are not reduced\n",
    "    pad = (kW - 1) // 2\n",
    "    image = cv2.copyMakeBorder(image, pad, pad, pad, pad, cv2.BORDER_REPLICATE)\n",
    "    output = np.zeros((iH, iW), dtype=\"float32\")\n",
    "    \n",
    "    # loop over the input image, \"sliding\" the kernel across each (x, y)-coordinate from left-to-right and top to bottom\n",
    "    for y in np.arange(pad, iH + pad):\n",
    "        for x in np.arange(pad, iW + pad):\n",
    "            # extract the ROI of the image by extracting the *center* region of the current (x, y)-coordinates dimensions\n",
    "            roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
    "            \n",
    "            # perform the actual convolution by taking the element-wise multiplicate between the ROI and the kernel, then summing the matrix\n",
    "            k = (roi * kernel).sum()\n",
    "            \n",
    "            # store the convolved value in the output (x,y)-coordinate of the output image\n",
    "            output[y - pad, x - pad] = k\n",
    "    \n",
    "    # rescale the output image to be in the range [0, 255]\n",
    "    output = rescale_intensity(output, in_range=(0, 255))\n",
    "    output = (output * 255).astype(\"uint8\")\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct average blurring kernels used to smooth an image\n",
    "- Create smallBlur as 7 x 7 filter\n",
    "- Create largeBlur as 21 x 21 filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct a Sharpening filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter2D( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Uses of Convolution in Image Processing\n",
    "- Blurring\n",
    "- Edge Detection\n",
    "- Classification of Images using Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have designed our own hand-engineered filter in the form of smallBlur, LargeBlur and so on\n",
    "\n",
    "### **What if there was a way to learn these filters instead?**\n",
    "Is it possible to define a machine learning algorithm that can look at images and eventually learn these types of operators?\n",
    "\n",
    "In fact, there is — these types of algorithms are a sub-type of Neural Networks called **Convolutional Neural Networks (CNNs)** \n",
    "\n",
    "CNNs are able to **learn filters** that can detect edges and blob-like structures in lower-level layers of the network — and then use the edges and structures as building blocks, eventually detecting higher-level objects (i.e., faces, cats, dogs, cups, etc.) in the deeper layers of the networ by applying the following\n",
    "- convolutional filters\n",
    "- nonlinear activation functions\n",
    "- pooling \n",
    "- backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
